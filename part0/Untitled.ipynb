{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(?, 2)\n",
      "(1000, 2)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "def affine_layer(hidden_dim, x, seed=0):\n",
    "    # x: a [batch_size x # features] shaped tensor.\n",
    "    # hidden_dim: a scalar representing the # of nodes.\n",
    "    # seed: use this seed for xavier initialization.\n",
    "\n",
    "    # START YOUR CODE\n",
    "\n",
    "    input_dim = x.get_shape()\n",
    "\n",
    "    w_ = tf.get_variable(\"w\", shape=[input_dim[1], hidden_dim],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=seed))\n",
    "    b_ = tf.get_variable(\"b\", shape=[hidden_dim],\n",
    "                        initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    return tf.matmul(x, w_) + b_\n",
    "\n",
    "    # END YOUR CODE\n",
    "\n",
    "def fully_connected_layers(hidden_dims, x):\n",
    "    # hidden_dims: A list of the width of the hidden layer.\n",
    "    # x: the initial input with arbitrary dimension.\n",
    "    # To get the tests to pass, you must use relu(.) as your element-wise nonlinearity.\n",
    "    #\n",
    "    # Hint: see tf.variable_scope - you'll want to use this to make each layer \n",
    "    # unique.\n",
    "\n",
    "    # START YOUR CODE\n",
    "    hidden_dim_length = len(hidden_dims)\n",
    "    for i in range(0, hidden_dim_length):\n",
    "        hidden_dim = hidden_dims[i]\n",
    "        with tf.variable_scope(str(i)):\n",
    "            x = tf.nn.relu(affine_layer(hidden_dim, x))\n",
    "    return x\n",
    "\n",
    "    # END YOUR CODE\n",
    "    \n",
    "def generate_data(num_train, num_test):\n",
    "    np.random.seed(1)\n",
    "    num = num_train + num_test\n",
    "    x0 = np.random.randn(num, 2) + 3.*np.array([1, 0])\n",
    "    x1 = np.random.randn(num, 2) + 1.*np.array([-1, 0])\n",
    "    X = np.vstack([x0, x1])\n",
    "    y = np.concatenate([\n",
    "        np.zeros(num), np.ones(num)])\n",
    "\n",
    "    # Randomly shuffle the data\n",
    "    shuf_idx = np.random.permutation(len(y))\n",
    "    X = X[shuf_idx]\n",
    "    y = y[shuf_idx]\n",
    "\n",
    "    return X[:num_train], y[:num_train], X[num_train:], y[num_train:]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "hidden_dims = []\n",
    "if len(hidden_dims) == 0:\n",
    "    input_dim = X.shape[1]\n",
    "else:\n",
    "    input_dim = hidden_dims[-1]\n",
    "\n",
    "print input_dim\n",
    "w_ = tf.Variable(tf.zeros([input_dim, 1], dtype=tf.float32), name=\"w\")\n",
    "b_ = tf.Variable(0.0, dtype=tf.float32, name=\"b\")\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, shape=[None, X.shape[-1]])\n",
    "\n",
    "X_train, y_train, X_test, y_test = generate_data(1000, 10)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(device_filters=\"/cpu:0\"))\n",
    "neural_net = fully_connected_layers(hidden_dims, x_ph)\n",
    "print neural_net.get_shape()\n",
    "print X_train.shape\n",
    "\n",
    "logits_ = tf.squeeze(tf.matmul(neural_net, w_)) + b_\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "out_val = sess.run(logits_, feed_dict={x_ph: X_train})\n",
    "\n",
    "print out_val\n",
    "#\n",
    "#tf.reset_default_graph()\n",
    "#\n",
    "#y_ph = tf.placeholder(tf.float32, shape=[None])\n",
    "#global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "#input_dim = X.shape[1]\n",
    "#print input_dim\n",
    "#w_ = tf.Variable(tf.zeros([input_dim, 1], dtype=tf.float32), name=\"w\")\n",
    "#b_ = tf.Variable(0.0, dtype=tf.float32, name=\"b\")\n",
    "\n",
    "#logits_ = tf.squeeze(tf.matmul(neural_net, w_)) + b_\n",
    "#y_hat = tf.sigmoid(logits_)\n",
    "#loss = tf.nn.sigmoid_cross_entropy_with_logits(y_hat, y_ph)\n",
    "#learning_rate = 0.001\n",
    "#optimizer_ = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "#train_op = optimizer_.minimize(loss)\n",
    "\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(device_filters=\"/cpu:0\"))\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#c, p, _ = sess.run([loss, y_hat, train_op],feed_dict={x_ph: X, y_ph: y})\n",
    "#loss_mean = tf.reduce_mean(c)\n",
    "#print sess.run(loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
